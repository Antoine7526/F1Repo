---
title: "Projet Formule 1"
author: "Batiste Amistadi, Charline Champ et Antoine Grancher"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_float: true
    toc_depth: 3
    number_sections: true
    theme: simplex
---
<div style="text-align: justify"> 

# Introduction 

Ce projet est né au cours de notre première année de master en Statistique et Sciences des Données dans le cadre d'une UE, nommée Logiciels spécialisés, où nous avons eu libre choix du sujet. Nous avons décidé, de manière collégiale, de le réaliser sur les résultats de la *Formule 1*. 
Ce projet a été essentiellement réalisé en présentiel pendant nos heures de cours, mais également lors de créneaux que nous nous étions fixés chaque semaine à la bibliothèque universitaire. Il arrivait parfois que l'on travaille de chez nous. Pour ce faire, nous avons utilisé *Discord* comme outil de communication et *GitHub* pour le partage et le versioning de nos codes. Enfin, le langage **```R```** a été utilisé pour l'ensemble du projet.  
Vous pouvez retrouver tout notre travail sur [*GitHub*](https://github.com/Antoine7526/F1Repo). La finalité de ce projet est une application Shiny disponible [ici](https://github.com/Antoine7526/F1Repo/blob/main/Shiny/3.4/shinyapp.R).   
Ce projet s'est divisé en quatre parties:

- le web scraping, afin de récupérer nos tableaux de données  
- l'implémentation des différentes fonctions permettant d'afficher des graphiques interactifs   
- la création d'un package qui regroupe toutes nos fonctions et tableaux de données  
- le développement d'une interface Shiny.    

Ce rapport sera divisé en trois parties. Tout d'abord, nous verrons tout ce qui a été relatif à la gestion du projet,  pour continuer, sa réalisation et enfin son évaluation générale.

# Gestion du projet

## Cahier des charges

|  |   |
|-----------------|-----------------------|
|  Contexte, définition du problème, motivations     |  Ce projet est né dans le cadre d'un cours, donné par Monsieur [Rémy Drouilhet](https://studio.dyndoc.fr/CoursM1R), spécialisé sur le langage **```R```**. Nous étions libre sur le choix et curieux de voir ce que pouvait donner de la visualisation de données sur la *Formule 1* (sur plusieurs années). |
| Objectifs    |  Utilisation de **```RMarkdown```**, **```ggplot2```**(optionnel) et **```Rcpp```** (optionnel). <br> Création d'une interface **```shiny```** et d'une librairie (package).  |
|   Périmètre    | Libre.  |
| Description fonctionelle | Pour commencer, le fichier WebScrapingVfinale.R doit être lancé pour récupérer les données. Nous obtenons sept bases de données de type *.csv*. Enfin, le fichier shinyapp.R doit être lancé pour avoir accés à l’interface et aux graphiques. L’utilisateur pourra choisir l’année qu’il souhaite entre 1950 et 2020 et de 1958 à 2020 pour les équipes.   |
| Délai |  	3 mois (du 16/09 au 05/12). |
| Livrable |  Code source réalisant la récupération des données, le traitement des données et l’interface shiny. <br> Une interface Web affichant les graphiques. <br> Un rapport. |


## Répartition des tâches

Pour la répartition des tâches, nous avons fixé dès le début, des objectifs à atteindre. Au fur et à mesure de l'avancement du projet, nous nous en sommes fixés de nouveaux en fonction du temps restant à disposition. A chaque fin de session de travail, un bilan était réalisé afin de faire le point sur l'avancement et pour se fixer les tâches à réaliser lors de la session suivante.  
Nous n'avons pas réalisé directement de diagramme de Gantt car compte tenu de ce que nous voulions mettre en avant, ou encore même de notre volume horaire disponible, il nous était compliqué de le réaliser en amont. Voici notre répartition globale des tâches par ordre chronologique :

- Antoine, Batiste, Charline : Début du [*web scraping*](https://github.com/Antoine7526/F1Repo/blob/main/WebScraping/WebscrapingV3.R).
- Antoine, Batiste, Charline : Création des graphiques avec **```ggplot2```** et **```plotly```**.
- Batiste : Création des [*bases de données*](https://github.com/Antoine7526/F1Repo/tree/main/DATA) avec le web scraping.
- Antoine, Batiste : Création des [*fonctions*](https://github.com/Antoine7526/F1Repo/tree/main/Fonctions) permettant la visualisation de données.
- Antoine: Création de fichiers [*test*](https://github.com/Antoine7526/F1Repo/tree/main/Test).
- Antoine : Implémentation de code [```Rcpp```](https://github.com/Antoine7526/F1Repo/tree/main/Rcpp).
- Antoine, Charline : Création du package [```VroumVroum```](https://github.com/CharlineChamp/VroumVroum).
- Charline : Développement de l'interface[```shiny```](https://github.com/Antoine7526/F1Repo/tree/main/Shiny).
- Antoine, Batiste, Charline : Rédaction du [*rapport*](https://github.com/Antoine7526/F1Repo/tree/main/Rapport) sous **```Rmarkdown```**.

# Réalisation 

## Récupération des données

Le web scraping consiste à récolter les données sur des sites web. Pour ce projet, basé sur la *Formule 1*, nous avons décidé de créer sept bases de données afin de produire des graphiques. Nous avons tout d'abord récupéré les données de l'année 2020 (*cf*. [WebscrapingV3.R](https://github.com/Antoine7526/F1Repo/blob/main/WebScraping/WebscrapingV3.R)) sur le site officiel de la [*Formule 1*](https://www.formula1.com/en/results.html). Nous avons ensuite développé notre code pour que chaque base de données soit composées des années 1950 à 2020. Pour la base de données  sur les équipes (**```dataTeams```**), elle commence en 1958 car les classements ont commencé  cette année là (*cf*.  [WebscrapingV4.R](https://github.com/Antoine7526/F1Repo/blob/main/WebScraping/WebscrapingV4.R)).  
Nous avons rencontré plusieurs problèmes lors de la récupération des données car le site avait une version mobile ce qui a nécessité un nettoyage des données (car celles-ci comportaient des caractères inutiles).
<br>



<br/>
Avec la base de données concernant les informations des pilotes par *Grand Prix* (**```dataDriversParRaces```**), nous avons eu un problème concernant la création des adresses *url* des pilotes. Une partie de *l'url* est créée à partir du nom du pilote, seulement certains noms étaient particuliers, ils étaient composés ou avaient un "de" ou un prénom ou un nom de moins de trois lettres. Nous avons donc dû faire une réécriture manuelle de cette partie du *l'url* pour ces pilotes (*cf*. [WebscrapingV4.R](https://github.com/Antoine7526/F1Repo/blob/main/WebScraping/WebscrapingV4.R) l.260 à 406).
<br>



<br/>
Pour les données concernant les positions de départ (**```dataStartingGrid```**), nous avons rencontré un autre problème lors du web scraping. *L'url* utilisée est de ce type :   
<span style="color:black">htt</span><span style="color:black">ps://www.formula1.com/en/results.html/</span> *année* <span style="color:black">/races/</span> *numéro unique associé à un grand prix* <span style="color:black">/</span> *nom du grand prix* <span style="color:black">/starting-grid.html</span>.  
Le problème vient que le numéro unique attribué à chaque grand prix n'a pas d'ordre logique (*cf*. [WebscrapingV4.R](https://github.com/Antoine7526/F1Repo/blob/main/WebScraping/WebscrapingV4.R) l.494). Pour régler cela, on a du parcourir manuellement les pages web pour créer la vraie liste des numéros associés à chaque grand prix.  
<br>



<br/>
Pour certaines fonctions, nous utilisions **```dataDriversParRaces```** et **```dataStartingGrid```**. Comme la première base de données contient l'ensemble des positions d'arrivées de chaque pilote et la deuxième, l'ensemble des positions de départ, nous nous attendions à avoir le même nombres de lignes. Or ce n'était pas toujours le cas. Ce problème vient du fait que sur le site officiel de la *Formule 1*, sont répertoriés (à l'endroit ou l'on récupèrait les positions d'arrivées) seulement les pilotes ayant gagné au moins un point sur la saison. Il était donc normal que nous nous retrouvions avec cette différence de lignes entre les deux bases de données. De ce problème en a découlé un nouveau, **```dataDrivers```**(notre base de données sensée contenir tous les pilotes) ne contenait pas tous les pilotes.  
<br>



<br/> 
Un autre problème qui aurait pu être identifié avant est que la starting grid où l'on récupère les données de dataStartingGrid n'est pas présente pour tous les grands prix entre 1950 et 1959 donc on avait pour certains grands prix des données fausses. On a donc décidé de changer de site pour créer les 3 bases de données citées.  
Pour palier à ce problème, nous avons décider de récolter nos données sur un autre site web: [*racing-statistics*](https://www.racing-statistics.com/en/seasons). Au lieu de récupèrer les données pilote par pilote pour chaque année, nous récoltons grand prix par grand prix pour chaque année. La taille des tableaux est une nouvelle fois différente mais ce processus nous a permis de gagner des données. Ce problème venait du fait que sur certains grand prix, des voitures pouvaient être copilotées, il y avait donc un pilote au départ mais deux à l'arrivée.  
Nous avons donc fait le choix de seulement sélectionner les pilotes qui sont partis pour régler ce problème.  
<br>



<br/>
Enfin, nous avons créé notre septième base de données contenant les longitudes et latitudes de chaque circuit. Ces données étaient présentes sur [*racing-statistics*](https://www.racing-statistics.com/en/seasons).  
  
Après avoir résolu tous nos soucis, nous obtenons nos sept base de données comme nous les voulions.

## Traitement des données 

Après avoir recueilli les données par web scraping, nous nous sommes tout de suite mis à réfléchir sur l’implémentation de fonctions permettant d’avoir une visualisation des données. Nous avons utilisé différents formats afin de donner une certaine diversité sur les graphiques. Nous avons utilisé :  
  
-	 Des diagrammes circulaires (en Donut) pour représenter des fréquences (dans notre cas pour le pourcentage de victoires des écuries sur une saison ou encore le pourcentage d’abandons des écuries sur une saison).  
  
-	Des diagrammes en barre pour représenter des fréquences ou des quantités (moyenne des points d’un pilote sur une saison, fréquences des positions finales des pilotes ayant fait le tour le plus rapide, nombres d’abandons par pilote, nombres d’abandons par grand prix)  
  
-	Des courbes, permettant la visualisation de l’évolution des points d’un pilote ou d’une écurie sur une saison.  
  
-	Un nuage de points, permettant d’obtenir une comparaison entre la position départ et la position d’arrivée.  
  
Toutes les fonctions permettent la visualisation sur une année et sur tous les grands prix. Seule la fonction permettant la comparaison entre la position de départ et la position d’arrivée fonctionne sur un seul grand prix.  
Nous avons décidé de ne pas prendre en compte la saison 2021 car elle est toujours en cours. Nos visualisations se concentrent donc de 1950 à 2020.  
<br>



<br/>
Toutes ces fonctions sont présentes dans le fichier [*VroumVroumFunc*](https://github.com/Antoine7526/F1Repo/tree/main/Fonctions)  et ont été réalisées sous **```plotly```** afin d’avoir des graphiques intéractifs. Il existe plusieurs versions de ce fichier. En effet, nous avons dû adapter nos fonctions en rapport avec les données recueillies.  
<br>



<br/>
Afin de tester ces fonctions, nous avons créé un fichier [*TestingFile*](https://github.com/Antoine7526/F1Repo/tree/main/Test). Ce dernier nous permet dans un premier temps de tirer au hasard une année entre 1950 et 2020, et un grand prix associé à l’année tirée. Cela nous permet de tester nos fonctions sur différentes années et sur différents grands prix.  
<br>



<br/>
Une fois nos fonctions nous paraissant opérationnelles, nous avons travaillé à l’élaboration d’un package nommé [*VroumVroum*](https://github.com/CharlineChamp/VroumVroum). Ce dernier nous permet de charger directement les fonctions, ce qui est très utile. Par la suite, après avoir obtenu nos bases de données finales, nous avons décidé de les ajouter directement au package. Cela a permis d’optimiser le temps de chargement de notre application shiny (*cf*. Partie 3).  
 <br>



<br/>
Pour continuer, nous avons également réalisé des fonctions en [**```Rcpp```**](https://github.com/Antoine7526/F1Repo/tree/main/Rcpp) (en mode *inLine*, en mode classique avec un fichier source *.cpp*). En mode *inLine*, nous avons implémenter une fonction **```add```** permettant l’addition entre trois éléments, et une **```nb_elt```** donnant le nombre d’éléments d’un vecteur de caractères. Dans le fichier *.cpp* nous avons fait deux fonctions calculant des moyennes, **```meanC```** et **```moyenne```**, l’un calculant la moyenne sur un vecteur de **```numeric```**, l’autre calculant la moyenne sur un tableau de **```int```** de taille $n$. Pour donner suite à cela nous avons voulu créer un package [*VroumVroumCpp*](https://github.com/Antoine7526/VroumVroumCpp). Nous nous sommes heurtés à des difficultés qui nous prenaient trop de temps. Or, les fonctions implémentées en **```Rcpp```** n'étaient pas utiles à notre projet, car nous ne les utilisions pas. Nous avons donc décidé de mettre cette partie de côté afin d’avancer sur le projet et d’y revenir plus tard si le temps nous le permettait.
<br>



<br/>

## Développement de l'interface Shiny

Pour le rendu de notre projet, nous avons créer une interface **```shiny```** permettant de présenter tous les éléments qui le constitue. C'est-à-dire nos graphiques, notre rapport ou encore nos liens sources. Le but étant d’avoir quelque chose d’intuitif nous permettant de le déposer sur internet pour faire perdurer le projet dans le temps. Dans cette partie, nous ne rentrerons pas en détail dans le code. Pour les plus curieux, vous pouvez vous rendre [ici](https://github.com/Antoine7526/F1Repo/blob/main/Shiny/3.5/shinyapp.R). 
<br>



<br/>
L’interface devait comprendre une structure simple : des éléments pour permettre à l’utilisateur de faire le choix des paramètres et une zone où le graphique s’affichera accompagné d'une petite interprétation. Pour le choix des paramètres, l’utilisateur doit pouvoir choisir l’année qu'il souhaite regarder. Et pour l'un des graphiques, il aura également le choix de sélectionner un grand prix.
<br>



<br/>
Le développement de notre interface web s'est fait en langage **```R```**, à l'aide du package **```shiny```** . Nous nous sommes exclusivement reposés sur cette librairie pour tout ce qui est de l’interface. La librairie **```shiny```** facilite la création d’applications web interactives directement à partir de **```R```**. Elle permet d’héberger des applications autonomes sur une page web ou les intégrer dans des documents **```RMarkdown```**. On peut également étendre les applications **```shiny```** avec des thèmes **```CSS```**, des widgets **```html```** et des actions **```JavaScript```**. Ce package combine la puissance de calcul de **```R```** avec l’interactivité du web.
<br>



<br/>
Un site internet est complétement dédié à la librairie **```shiny```**. Il est composé d’explications pour chaque fonction disponible dans ce package, il y a une partie avec de nombreux articles qui expliquent pas à pas le processus pour construire une interface web. Il nous offre aussi une large galerie de sites internets développés sous ce package, vous pouvez le retrouver [ici](https://shiny.rstudio.com/gallery/). Nous nous en sommes beaucoup servis car il nous suffisait d’aller chercher un site sur lequel il y avait ce que nous voulions, puis d’aller voir le code qui était fourni avec pour comprendre les mécanismes.  
<br>



<br/>
Pour vous expliquer brièvement le code, il se constitue de deux grosses fonctions essentielles au fonctionement de l’application : 

- une fonction **```ui```**
- une fonction **```server```**

Dans la fonction **```ui```** nous retrouvons tout ce qui touche à la mise en page : la disposition des éléments, les couleurs, les polices, les onglets, la manière dont les graphiques s’affichent, etc...   
<br>



<br/>
Comme cité plus tôt, lors de ce projet nous avons créé un package nommée [*VroumVroum*](https://github.com/CharlineChamp/VroumVroum). Dans ce package, nous avons toutes nos fonctions utiles aux traitements de nos données, c'est-à-dire à l'affichage de nos différents graphiques. Egalement sont présentes dans ce package, toutes nos données récupérées à l'aide du web scraping. Ainsi dans la fonction **```server```**, nous avons principalement utilisé ce package. Le processus reste le même, nous avons créé une fonction pour chaque graphique à afficher. Dans nos fonctions nous avons commencé par filtrer les données par rapport à l'année sélectionnée par l'utilisateur, ou encore même par le grand prix. Ensuite il nous suffisait d'appeler nos fonctions présentes dans le package et d'y insérer nos données filtrées. L'ajout de ce package nous a permis d'obtenir un code, pour l'interface web, relativement ahéré, moins brouillon et facile à comprendre. Cela est très utile pour quelqu'un qui souhaiterait le reprendre.  
<br>



<br/>
Une fois l’application créée, il est très facile de la publier sur internet. Nous avons déployé l’application sur un serveur de la librairie shiny : shinyapps.io. 


# Evaluation générale

## Difficultées rencontrées

Discutons maintenant des différentes difficultés rencontrées lors de ce projet.
<br>



<br/>
Comme nous l'avons vu précedemment, la récupération des données nous a posé quelques problèmes: la génération automatique des liens pour récupérer les données, l'incohérence entre le nombre de pilotes aux départs et le nombre de pilotes à l'arrivée, etc... Cependant un autre problème est apparu. En effet, durant plus de la moitié du projet, nous avons eu des problèmes d'accents et caractères spéciaux lorsque l'on s'échangeait les données et fichiers R. Ainsi une partie du groupe a dû relancer les fichiers de web scraping afin d'avoir des données sans anomalies. Après réflexion, nous nous sommes rendu compte que le problème venait du type d'encodage des fichiers. En effet, nous n'avons pas tous les mêmes systèmes d'exploitation.
<br>



<br/>
Pour continuer, un autre souçi est apparu, le Rcpp. La création d'un package est le principal problème pour le Rcpp. En effet, malgré les différentes méthodes employées, que ce soit par *Rstudio* ou par le terminal, rien ni faisait. Nous avions beau suivre les indications, nous ne tombions jamais sur le résultat escompté. Cela venait peut être des types déclaré dans les fonctions *.cpp*. Nous n'avons pas réellement chercher d'où venait l'erreur, car beaucoup de travail était en cours et comme nous l'avons déjà dit plus haut, ces fonctions n'auraient jamais été utilisées lors ce projet. Il n'était donc pas très pertinent d'en faire un package.
<br>



<br/>
Enfin, la création du package **```VroumVroum```** n'a pas été une mince affaire. En effet, nous voulions que les librairies utilisées dans nos fonctions s'installent automatiquement (si elles n'étaient pas déjà présentes) lors de l'installation de notre package. Une fois ce problème résolu, un second est apparu. Nous avions eu ce que nous pouvons appeler un conflit de librairies. Nous utilisons dans le package **```VroumVroum```** les librairies **```ggplot2```** et **```plotly```**. Pour vous expliquer brièvement, **```ggplot2```** nous pertmet d'afficher des graphiques de qualités et **```plotly```** nous permet de les rendre intéractif. Ce que nous faisions est de transformer un objet **```ggplot2```** en un objet **```plotly```** via la fonction **```ggplotly()```**. Cette dernière fait apelle à une autre fonction : **```last_plot()```** qui est présentes dans les deux libraires. Ce qui entraînait un conflit.  
Afin de  résoudre ce problème, nous avons dû, au lieu d'importer tous le package **```ggplot2```** et **```plotly```**, importer uniquement les fonctions dont nous avions besoin.

## Pistes d'améliorations

golem <- shiny
questionnaire

# Conclusion 

Pour finir, nous avons fait le choix de faire une conclusion personnelle sur ce projet plutôt qu'une conclusion générale.

Antoine :



Batiste :

Ce projet m'a beaucoup plu, tant le sujet que le résultat final obtenu. J'ai pu approfondir mes compétences de **```ggplot2```** mais aussi pu découvrir la création de package de **```R``` ** et manipuler de nouvelles librairies notamment **```rvest```** pour le web scraping et l'utilisation de *GitHub*. Je trouve que travailler sous forme de projet avec une grande autonomie est bien plus formateur et plus épanouissant que si on avait eu des cours standards.

Charline :

Pour ma conclusion personnelle, je pense qu’il est important de commencer par dire que j’ai apprécié réaliser ce projet avec mes camarades. Cela m’a permis d’acquérir de nouvelles connaissances en **```R``` ** et de me rendre compte de ce que je suis capable de faire. J'ai pu approndir mes connaissances pour la création d'une application shiny et me découvrir une réelle passion pour cela. De plus, j'ai pu acquérir des connaissances en terme de création de package ou encore même d'utilisation du package **```ggplot2```** (ou **```plotly```**). Etre livré à nous même nous a été que bénéfique. 

# Remerciement

Nous tenons à remercier Louis Piard pour avoir réalisé le logo de notre application.
<br>



<br/>
<center>
<img src='logof1_1.png' height = '196'  width ='258'>
<center/>

# Bibliographie
  
<font size = "3">
<u> <B> Web Scraping : </B> </u>
</font>  
  
1. Site officiel de la Formule 1,
https://www.formula1.com/

2. Site de données sur la Formule 1,
https://www.racing-statistics.com/en

<font size = "3">
<u> <B> Traitement des Données : </B> </u>
</font>  
  
3. "ggplot2 graduation des axes",
http://www.sthda.com/french/wiki/ggplot2-graduation-des-axes-guide-pour-personnaliser-les-etiquettes-des-graduations-logiciel-r-et-visualisation-de-donnees

4. "suppression espaces superflus", 2011,
http://forums.cirad.fr/logiciel-R/viewtopic.php?t=4446

5. "Donut chart with ggplot2", 
https://www.r-graph-gallery.com/128-ring-or-donut-plot.html

6. "Pie Charts in R", 
https://plotly.com/r/pie-charts/

<font size = "3">
<u> <B> Rcpp : </B> </u>
</font>  
  
7. "High performance functions with Rcpp", Hadley Wickham, 
http://adv-r.had.co.nz/Rcpp.html

8. "Writing a package that uses Rcpp", Dirk Eddelbuettel et Romain François,
https://cran.r-project.org/web/packages/Rcpp/vignettes/Rcpp-package.pdf

9. "Thirteen Simple Steps for Creating An R Package with an External C++ Library", Dirk Eddelbuettel, https://cran.r-project.org/web/packages/Rcpp/vignettes/Rcpp-libraries.pdf

<font size = "3">
<u> <B> Création Package : </B> </u>
</font>  
  
10. "Package Development: : CHEAT SHEET", 
https://rawgit.com/rstudio/cheatsheets/master/package-development.pdf

11. "Including datasets", Karl Broman, 
https://kbroman.org/pkg_primer/pages/data.html

<font size = "3">
<u> <B> Interface Web : </B> </u>
</font>  
  
12. "ioslides presentation", 
https://bookdown.org/yihui/rmarkdown/ioslides-presentation.html

13. "Presentations with ioslides", 
https://garrettgman.github.io/rmarkdown/ioslides_presentation_format.html

14. "Communicating with Shiny via JavaScript", Joe Cheng, https://shiny.rstudio.com/articles/communicating-with-js.html

15. "Name of icon", 
https://fontawesome.com/v6.0/icons?q=Car&p=2&s=solid%2Cbrands%2Cregular%2Clight%2Cthin%2Cduotone

16. "Introduction to R dashboard development with Shiny Dashboard", Anastasia Lucas, https://www.youtube.com/watch?v=wSYt4IYIsdI

17. "Dashboard avec shiny", 
https://alisonjollois.github.io/r-shiny/jour2-shiny.html

18. "Background: Shiny and HTML", 
https://rstudio.github.io/shinydashboard/structure.html

19. "Application layout guide",Jj Allaire, 
https://shiny.rstudio.com/articles/layout-guide.html

<font size = "3">
<u> <B> GitHub : </B> </u>
</font>  
  
20. Dépôt git du projet,
https://github.com/Antoine7526/F1Repo

21. Package VroumVroum,
https://github.com/CharlineChamp/VroumVroum

</div>

