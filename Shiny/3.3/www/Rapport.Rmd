---
title: "Projet Formule 1"
author: "Batiste Amistadi, Charline Champ et Antoine Grancher"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_float: true
    toc_depth: 3
    number_sections: true
    theme: simplex
---
# Introduction 

Ce projet est né lors de notre première année de master en Statistique et Sciences des données. En effet, dans le cadre de l'UE nommée Logiciels spécialisées nous avons eu carte blanche concernant ce projet. Nous avons donc décidé de le réaliser sur les résultats de la Formule 1. Le choix de la Formule 1 s'est porté sur le fait que l'intégralité de notre groupe trouvait ce domaine intéressant. Concernant la réalisation de ce projet elle a été faite en présentiel pendant nos heures de cours cependant nous avons également fait le choix de chaque semaines nous retrouvez pour poursuivre notre travail. Pour le code, nous avons utilisé le langage R et pour tout ce qui était communication, nous avons exploité l'outil Discord et git. Notre git est disponible sur [*GitHub*](https://github.com/Antoine7526/F1Repo). La finalité de ce projet est une application Shiny disponible sur [*ProjetF1*](https://github.com/Antoine7526/F1Repo).   
Le projet a été divisé en quatre grandes parties: le web-scraping pour récupérer nos tableaux de données, la création des differences fonctions pour afficher les graphiques interactifs, la création d'un package qui regroupe nos fonctions et données et enfin le développement de l'interface Shiny. Cependant ce rapport est divisé en trois parties la gestion du projet, sa réalisation et enfin son évaluation générale.

# Gestion du projet

## Cahier des charges

|  |   |
|-----------------|-----------------------|
|  Contexte, définition du problème, motivations     |  Ce projet est né dans le cadre d'un projet à réaliser en R suite aux cours de Rémy Drouillet. On était curieux de voir des informations graphiques sur la formule 1 sur plusieurs années. |
| Objectifs    |  Utilisation de RMarkdown, ggplot(optionnel) et rcpp (optionnel). <br> Création d'une interface Shiny et d'une librarie(optionnel).  |
|   Périmètre    | Libre.  |
| Description fonctionelle | En premier lieu le fichier WebScrapingVfinale.R doit être lancé pour récupérer les données, on obtient 6 bases de données de type .csv. En deuxième lieu le fichier shinyapp.R doit être lancé pour avoir accés à l’interface et aux graphiques. L’utilisateur pourra choisir l’année qu’il souhaite entre 1950 et 2020 et de 1958 à 2020 pour les équipes.   |
| Délai |  	3 mois (du 16/09 au 05/12). |
| Livrable |  Code source réalisant la récupération des données, le traitement des données et l’interface shiny. <br> Une interface Web affichant les graphiques. <br> Un rapport. |


## Répartition des tâches

Pour la répartition des tâches lors de ce projet, nous avons fixé dés le début les objectifs à atteindre et au fur et à mesure de notre avancée  nous avons ajouté d'autres défis optionnels à réaliser qui dépendaient de la contrainte du temps. Nous avons fait le choix de réaliser des "réunions" à chaque fin de session de travail pour se fixer les tâches à faire à la session suivante. Nous n'avons pas réalisé directement un diagramme de Gantt car étant donné le flou présent sur ce que nous voulions mettre en avant dans ce projet ou encore même notre volume horaire disponible il nous été compliqué de le réaliser en amont. Voici donc notre répartition globale des tâches par ordre chronologique :

- Antoine, Batiste, Charline : Début du [*web scraping*](https://github.com/Antoine7526/F1Repo/blob/main/WebScraping/WebscrapingV3.R).
- Antoine, Batiste, Charline : Création des graphiques avec ggplot et plotly.
- Batiste : Création des [*bases de données*](https://github.com/Antoine7526/F1Repo/tree/main/DATA) avec le web scraping.
- Antoine, Batiste : Création des [*fonctions des graphiques*](https://github.com/Antoine7526/F1Repo/tree/main/Fonctions).
- Antoine : Implémentation de code [*Rcpp*](https://github.com/Antoine7526/F1Repo/tree/main/Rcpp).
- Antoine, Charline : Création du [*package VroumVroum*](https://github.com/CharlineChamp/VroumVroum).
- Charline : Développement de l'[*interface Shiny*](https://github.com/Antoine7526/F1Repo/tree/main/Shiny).
- Antoine, Batiste, Charline : Rédaction du [*rapport*](https://github.com/Antoine7526/F1Repo/tree/main/Rapport) sous R markdown.

# Réalisation 

## Récupération des données

Le web scraping consiste à récolter des données sur des sites web. Pour ce projet basé sur la formule 1, nous avons décidé de créer 6 bases de données qui nous aiderons par la suite à produire des graphiques. Dans un premier temps nous avons récupéré l'année 2020 (cf WebscrapingV3.R) sur le site officiel de la [*formule 1*](https://www.formula1.com/en/results.html). Suite à cela, nous avons développé un nouveau code cette fois-ci rassemblant toutes les données de 1950 à 2020, hormis pour les équipes où les classements ont commencé qu'en 1958 (cf WebscrapingV4.R). En récupérant ses données nous avons rencontré plusieurs problèmes notamment car le site avait une version portable. Nous avons donc dû nettoyage les données de caractères inutiles.
<br>



<br/>
Avec la base de données nommée dataDriversParRaces qui correspond aux données des pilotes par circuits, nous avons eu un plus gros problème concernant la création des adresses url des pilotes. Une partie de l'url est créée à partir du nom du pilote, seulement certains noms étaient particuliers, ils étaient composés ou avaient un "de" ou un prénom ou nom de moins de 3 lettres. On a donc du faire une réécriture manuelle de cette partie du l'url pour ces pilotes (cf WebscrapingV4.R lignes 260 à 406).
<br>



<br/>
Concernant la base de données dataStartingGrid qui, comme son nom l'indique correspond aux positions à laquelle les pilotes vont partir, nous a également causé un autre problème du web scraping. L'url utilisée est de ce type :   
<span style="color:black">htt</span><span style="color:black">ps://www.formula1.com/en/results.html/</span> année <span style="color:black">/races/</span> numéro unique associé à un grand prix <span style="color:black">/</span> nom du grand prix <span style="color:black">/starting-grid.html</span>. Ainsi le problème rencontré a été que le numéro unique attribué à chaque grand prix n'avait pas d'ordre logique (cf WebscrapingV4.R ligne 494).
<br>



<br/>
Ensuite, une autre problème a survenu. Pour certains graphiques nous utilisons les données de deux bases de données présentés précedemment, nous nous sommes rendu compte que pour certaines années nous n'avions pas le même nombre de lignes entre ces deux bases. Or si l'on réfléchit la première base nous renvoit les pilotes sur chaque grand prix à l'arrivée et l'autre les pilotes de chaque grand prix au départ. Après une observation plus poussée sur le site nous nous sommes rendu compte que cela venait du fait que là où¹ l'on récupèrait le nom des pilotes, nous n'avions que les pilotes qui ont eu au moins 1 point dans l'année ainsi pour les autres qui n'ont pas eu de points il n'y a pas de lien pour récupérer ces données.  
De ce problème on a identifié un nouveau problème dans la base de données dataDrivers, qui recence tous les noms des pilotes, qui ainsi ne contenait pas tous les pilotes par année. Nous avons donc fait des recherches qui nous ont décidé de changer de site web pour la récupération de nos données. Ce qui nous a permit d'au lieu de faire pilote par pilote par année, nous récoltons les données grand prix par grand prix par année. Lorsque nous avons comparé la taille de nos bases de données dataDriversParRace et dataStartingGrid nous avons remarqué une nouvelle fois une taille différente. Cependant nous avions gagné des données. En anaysant une fois de plus ce nouvelle problème nous avons remarqué cette fois-ci qu'il venait que certaines voitures sont copilotées et qu'il y a un pilote au départ et 2 à l'arrivée par exemple.   
Un autre problème lié à notre premier lien source, qui aurait pu être identifié avant, est que la starting grid où l'on récupère les données de dataStartingGrid n'est pas présente pour tous les grands prix entre 1950 et 1959. Ainsi nous avions pour certains grands prix des données fausses. Nous avions donc fait le choix de changer de site web pour créer les trois bases de données citées.
<br>



<br/>
Ce nouveau lien source est disponible sur le site [*racing-statistics*](https://www.racing-statistics.com/en/seasons) où nous avons également eu des problèmes entre les pilotes de départ et d'arrivée. Epuisé par ce problème récurent, nous avons prit la décision de sélectionner pour les données d'arrivée uniquement celles des pilotes qui sont partit.La perte d'information que nous choissons concernent les pilotes qui étaient à l'arrivée et pas au départ, ils étaient en général des pilotes qui n'avaient pas pris les départs mais qui étaient dans la grille d'arrivée problablement une erreur du site.  
Finalement nous obtientons grâce au fichier WebscrapingVfinale.R nos six bases de données sans erreur.

## Traitement des données 

Après avoir recueilli les donné par web scraping, nous nous sommes tout de suite mis à réfléchir sur l’implémentation de fonctions permettant d’avoir une visualisation des données. Nous avons utilisé différents formats afin de donner une certaine diversité sur les graphiques. Nous avons utilisé :  
  
-	 Des diagrammes circulaires (en Donut) pour représenter des fréquences (dans notre cas pour le pourcentage de victoire des écuries sur une saison ou encore le pourcentage d’abandon des écuries sur une saison).  
  
-	Des diagrammes en barre pour représenter des fréquences ou des quantités (moyenne des points d’un pilote sur une saison, fréquence des positions finales des pilotes ayant fait le tour le plus rapide, nombre d’abandons par pilote, nombre d’abandon par grand prix)  
  
-	Des courbes, permettant la visualisation de l’évolution des points d’un pilote ou d’une écurie sur une saison.  
  
-	Un nuage de points, permettant d’obtenir une comparaison entre la position départ et la position d’arrivée.  
  
Toutes les fonctions permettent la visualisation sur une année et tous les grands prix. Seule la fonction permettant la comparaison entre la position de départ et la position d’arrivée fonctionne sur un seul grand prix. Nous avons décidé de ne pas prendre en compte la saison 2021 car elle est toujours en cours. Nos visualisations se concentrent donc de 1950 à 2020.  
  
Toutes ces fonctions sont présentes dans le fichier [*VroumVroumFunc*](https://github.com/Antoine7526/F1Repo/tree/main/Fonctions)  et ont été réalisées sous *plotly* afin d’avoir des graphiques dynamiques. Il existe plusieurs versions de ce fichier. En effet, nous avons dû adapter nos fonctions en fonction des données recueillies.  
  
Afin de tester ces fonctions, nous avons créé un fichier [*TestingFile*](https://github.com/Antoine7526/F1Repo/tree/main/Test). Ce dernier nous permet dans un premier temps de tiré au hasard une année entre 1950 et 2020, et un grand prix associé à l’année tirée. Cela nous permet de tester nos fonctions sur différentes années et différents grands prix.  
  
Une fois nos fonctions nous paraissant opérationnelles, nous avons travaillé à l’élaboration d’un package nommé [*VroumVroum*](https://github.com/CharlineChamp/VroumVroum). Ce dernier nous permet de charger directement les fonctions, ce qui est très utile. Par la suite, après avoir obtenue nos data frames finals, nous avons décidé de les ajouter directement aux package. Cela a permis d’optimiser le temps de chargement de notre application *shiny* (cf. Partie 3).  
  
Pour continuer, nous avons également réalisé des fonctions en [*Rcpp*](https://github.com/Antoine7526/F1Repo/tree/main/Rcpp) (en mode *inLine*, en mode classique avec un fichier source *.cpp*). En mode *inLine*, nous avons implémenter une fonction    « *add* » permettant l’addition entre trois éléments, et une « *nb_elt* » donnant le nombre d’élément d’un vecteur de caractères. Dans le fichier *.cpp* nous avons fait deux fonctions calculant des moyennes, « *meanC* » et « *moyenne* », l’un calculant la moyenne sur un vecteur de *numeric*, l’autre calculant la moyenne sur un tableau de *int* de taille *n*. Pour donner suite à cela nous avons voulons créer un package [*VroumVroumCpp*](https://github.com/Antoine7526/VroumVroumCpp). Nous nous sommes heurté à des difficultés qui nous prenaient pas mal de temps. Or, les fonctions implémentées en *Rcpp* n'étaient pas utiles à notre projet, car nous ne les utilisions pas. Nous avons donc décidé de mettre cette partie de côté afin d’avancer sur le projet et d’y revenir plus tard si le temps nous le permettrait.

## Développement de l'interface Shiny

# Evaluation générale

## Difficultées rencontrées

Comme il a été dit ci dessus, le web scraping et le Rcpp nous ont posé des problèmes. La création d'un package est le principal problème pour le Rcpp.

Durant la moitié du projet, on a eu des problèmes d'accents et caractères spéciaux quand on s'échangeait les données et fichiers R. On s'est rendu compte que le problème venait du type d'encodage des fichiers de chacun et du système d'exploitation.

## Pistes d'améliorations

# Conclusion 

Pour finir, nous avons fait le choix de faire une conclusion personnelle sur ce projet plutôt qu'une conclusion générale.

Antoine :



Batiste :

Ce projet m'a beaucoup plu, tant le sujet que le résultat final obtenu. J'ai pu approfondir mes compétences de ggplot2 mais aussi pu découvrir la création de package de R et manipuler de nouvelles librairies notamment rvest pour le web scraping et l'utilisation de Git. Je trouve que travailler sous forme de projet avec une grande autonomie est bien plus formateur et plus épanouissant que si on avait eu des cours standards.

Charline :

Pour ma conclusion personnelle, je pense qu’il est important de commencer par dire que j’ai adoré réaliser ce projet avec mes camarades. Cela m’a permis d’acquérir de nouvelles connaissances en R et de me rendre compte de ce que je suis capable de faire. J'ai pu approndir mes connaissances pour la création d'une application shiny et me découvrir une réelle passion pour cela. Etre livré à nous même nous a beaucoup plus était formateur. 

# Bibliographie





