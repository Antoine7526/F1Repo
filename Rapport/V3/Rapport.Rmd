---
title: "Projet Formule 1"
author: "Batiste Amistadi, Charline Champ et Antoine Grancher"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_float: true
    toc_depth: 3
    number_sections: true
    theme: simplex
---
# Introduction 

Ce projet est né au cours de notre première année de master en Statistique et Sciences des Données dans le cadre d'une UE, nommée Logiciels spécialisés, où nous avons eu libre choix du sujet. Nous avons décidé, de manière collégiale, de le réaliser sur les résultats de la *Formule 1*. 
Ce projet a été essentiellement réalisé en présentiel pendant nos heures de cours, mais également lors de créneaux que nous nous étions fixés chaque semaine à la bibliothèque universitaire. Il arrivait parfois que l'on travaille de chez nous. Pour ce faire, nous avons utilisé *Discord* comme outil de communication et *GitHub* pour le partage et le versioning de nos codes. Enfin, le langage **```R```** a été utilisé pour l'ensemble du projet.  
Vous pouvez retrouver tout notre travail sur [*GitHub*](https://github.com/Antoine7526/F1Repo). La finalité de ce projet est une application Shiny disponible [ici](https://github.com/Antoine7526/F1Repo/blob/main/Shiny/3.4/shinyapp.R).   
Ce projet s'est divisé en quatre parties:

- le web scraping, afin de récupérer nos tableaux de données  
- l'implémentation des differentes fonctions permettant d'afficher des graphiques interactifs   
- la création d'un package qui regroupe toutes nos fonctions et tableaux de données  
- le développement d'une interface Shiny.    

Ce rapport sera divisé en trois parties. Tout d'abord, nous verrons tout ce qui a été relatif à la gestion du projet,  pour continuer, sa réalisation et enfin son évaluation générale.

# Gestion du projet

## Cahier des charges

|  |   |
|-----------------|-----------------------|
|  Contexte, définition du problème, motivations     |  Ce projet est né dans le cadre d'un cours, donné par Monsieur [Rémy Drouilhet](https://studio.dyndoc.fr/CoursM1R), spécialisé sur le langage **```R```**. Nous étions libre sur le choix et curieux de voir ce que pouvait donner de la visualisation de données sur la *Formule 1* (sur plusieurs années). |
| Objectifs    |  Utilisation de **```RMarkdown```**, **```ggplot2```**(optionnel) et **```Rcpp```** (optionnel). <br> Création d'une interface **```shiny```** et d'une librairie (package).  |
|   Périmètre    | Libre.  |
| Description fonctionelle | Pour commencer, le fichier WebScrapingVfinale.R doit être lancé pour récupérer les données. Nous obtenons sept bases de données de type *.csv*. Enfin, le fichier shinyapp.R doit être lancé pour avoir accés à l’interface et aux graphiques. L’utilisateur pourra choisir l’année qu’il souhaite entre 1950 et 2020 et de 1958 à 2020 pour les équipes.   |
| Délai |  	3 mois (du 16/09 au 05/12). |
| Livrable |  Code source réalisant la récupération des données, le traitement des données et l’interface shiny. <br> Une interface Web affichant les graphiques. <br> Un rapport. |


## Répartition des tâches

Pour la répartition des tâches, nous avons fixé dès le début, des objectifs à atteindre. Au fur et à mesure de l'avancement du projet, nous nous en sommes fixés de nouveaux en fonction du temps restant à disposition. A chaque fin de session de travail, un bilan était réalisé afin de faire le point sur l'avancement et pour se fixer les tâches à réaliser lors de la session suivante.  
Nous n'avons pas réalisé directement de diagramme de Gantt car compte tenu de ce que nous voulions mettre en avant, ou encore même de notre volume horaire disponible, il nous était compliqué de le réaliser en amont. Voici notre répartition globale des tâches par ordre chronologique :

- Antoine, Batiste, Charline : Début du [*web scraping*](https://github.com/Antoine7526/F1Repo/blob/main/WebScraping/WebscrapingV3.R).
- Antoine, Batiste, Charline : Création des graphiques avec **```ggplot2```** et **```plotly```**.
- Batiste : Création des [*bases de données*](https://github.com/Antoine7526/F1Repo/tree/main/DATA) avec le web scraping.
- Antoine, Batiste : Création des [*fonctions*](https://github.com/Antoine7526/F1Repo/tree/main/Fonctions) permettant la visualisation de données.
- Antoine: Création de fichiers [*test*](https://github.com/Antoine7526/F1Repo/tree/main/Test).
- Antoine : Implémentation de code [```Rcpp```](https://github.com/Antoine7526/F1Repo/tree/main/Rcpp).
- Antoine, Charline : Création du package [```VroumVroum```](https://github.com/CharlineChamp/VroumVroum).
- Charline : Développement de l'interface[```shiny```](https://github.com/Antoine7526/F1Repo/tree/main/Shiny).
- Antoine, Batiste, Charline : Rédaction du [*rapport*](https://github.com/Antoine7526/F1Repo/tree/main/Rapport) sous **```Rmarkdown```**.

# Réalisation 

## Récupération des données

Le web scraping consiste à récolter les données sur des sites web. Pour ce projet, basé sur la *Formule 1*, nous avons décidé de créer sept bases de données afin de produire des graphiques. Nous avons tout d'abord récupérer les données de l'année 2020 (*cf*. [WebscrapingV3.R](https://github.com/Antoine7526/F1Repo/blob/main/WebScraping/WebscrapingV3.R)) sur le site officiel de la [*Formule 1*](https://www.formula1.com/en/results.html). Nous avons ensuite développé notre code pour que chaque base de données soit composées des années 1950 à 2020. Pour la base de données  sur les équipes (**```dataTeams```**), elle commence en 1958 car les classements ont commencé  cette année là (*cf*.  [WebscrapingV4.R](https://github.com/Antoine7526/F1Repo/blob/main/WebScraping/WebscrapingV4.R)).  
Nous avons rencontré plusieurs problèmes lors de la récupération des données car le site avait une version mobile ce qui a nécessité un nettoyage des données (car celles-ci comportaient des caractères inutiles).
<br>



<br/>
Avec la base de données concernant les informations des pilotes par *Grand Prix* (**```dataDriversParRaces```**), nous avons eu un problème concernant la création des adresses *url* des pilotes. Une partie de *l'url* est créée à partir du nom du pilote, seulement certains noms étaient particuliers, ils étaient composés ou avaient un "de" ou un prénom ou un nom de moins de trois lettres. Nous avons donc dû faire une réécriture manuelle de cette partie du *l'url* pour ces pilotes (*cf*. [WebscrapingV4.R](https://github.com/Antoine7526/F1Repo/blob/main/WebScraping/WebscrapingV4.R) l.260 à 406).
<br>



<br/>
Pour les données concernant les positions de départ (**```dataStartingGrid```**), nous avons rencontré un autre problème lors du web scraping. *L'url* utilisée est de ce type :   
<span style="color:black">htt</span><span style="color:black">ps://www.formula1.com/en/results.html/</span> *année* <span style="color:black">/races/</span> *numéro unique associé à un grand prix* <span style="color:black">/</span> *nom du grand prix* <span style="color:black">/starting-grid.html</span>.  
Le problème vient que le numéro unique attribué à chaque grand prix n'a pas d'ordre logique (*cf*. [WebscrapingV4.R](https://github.com/Antoine7526/F1Repo/blob/main/WebScraping/WebscrapingV4.R) l.494). Pour régler cela, on a du parcourir manuellement les pages web pour créer la vraie liste des numéros associés à chaque grand prix.  
  
<br>



<br/>
Pour certaines fonctions, nous utilisions **```dataDriversParRaces```** et **```dataStartingGrid```**. Comme la première base de données contient l'ensemble des positions d'arrivées de chaque pilote et la deuxième, l'ensemble des positions de départ, nous nous attendions à avoir le même nombres de lignes. Or ce n'était pas toujours le cas. Ce problème vient du fait que sur le site officiel de la *Formule 1*, sont répertoriés (à l'endroit ou l'on récupèrait les positions d'arrivées) seulement les pilotes ayant gagné au moins un point sur la saison. Il était donc normal que nous nous retrouvions avec cette différence de lignes entre les deux bases de données. De ce problème en a découlé un nouveau, **```dataDrivers```**(notre base de données sensée contenir tous les pilotes) ne contenait pas tous les pilotes.  
  
Pour palier à ce problème, nous avons décider de récolter nos données sur un autre site web :[*racing-statistics*](https://www.racing-statistics.com/en/seasons). Au lieu de récupèrer les données pilote par pilote pour chaque année, nous récoltons grand prix par grand prix pour chaque année. La taille des tableaux est une nouvelle fois différente mais ce processus nous a permis de gagner des données. Ce problème venait du fait que sur certains grand prix, des voitures pouvaient être copilotées, il y avait donc un pilote au départ mais deux à l'arrivée.  
Nous avons donc fait le choix de seulement sélectionner les pilotes qui sont partis pour régler ce problème.  
  
(**voir avec Batiste**)  
Un autre problème qui aurait pu être identifié avant est que la starting grid où l'on récupère les données de dataStartingGrid n'est pas présente pour tous les grands prix entre 1950 et 1959 donc on avait pour certains grands prix des données fausses. On a donc décidé de changer de site pour créer les 3 bases de données citées.  
  
Ensuite, nous avons créé notre septième base de données qui contenait les longitudes et latitudes de chaque circuit sur le 2e site [*racing-statistics*](https://www.racing-statistics.com/en/seasons).  
  
Après avoir résolu tous nos soucis, nous obtenons nos sept base de données comme nous les voulions.

## Traitement des données 

Après avoir recueilli les données par web scraping, nous nous sommes tout de suite mis à réfléchir sur l’implémentation de fonctions permettant d’avoir une visualisation des données. Nous avons utilisé différents formats afin de donner une certaine diversité sur les graphiques. Nous avons utilisé :  
  
-	 Des diagrammes circulaires (en Donut) pour représenter des fréquences (dans notre cas pour le pourcentage de victoires des écuries sur une saison ou encore le pourcentage d’abandons des écuries sur une saison).  
  
-	Des diagrammes en barre pour représenter des fréquences ou des quantités (moyenne des points d’un pilote sur une saison, fréquences des positions finales des pilotes ayant fait le tour le plus rapide, nombres d’abandons par pilote, nombres d’abandons par grand prix)  
  
-	Des courbes, permettant la visualisation de l’évolution des points d’un pilote ou d’une écurie sur une saison.  
  
-	Un nuage de points, permettant d’obtenir une comparaison entre la position départ et la position d’arrivée.  
  
Toutes les fonctions permettent la visualisation sur une année et sur tous les grands prix. Seule la fonction permettant la comparaison entre la position de départ et la position d’arrivée fonctionne sur un seul grand prix.  
Nous avons décidé de ne pas prendre en compte la saison 2021 car elle est toujours en cours. Nos visualisations se concentrent donc de 1950 à 2020.  
  
Toutes ces fonctions sont présentes dans le fichier [*VroumVroumFunc*](https://github.com/Antoine7526/F1Repo/tree/main/Fonctions)  et ont été réalisées sous **```plotly```** afin d’avoir des graphiques intéractifs. Il existe plusieurs versions de ce fichier. En effet, nous avons dû adapter nos fonctions en rapport avec les données recueillies.  
  
Afin de tester ces fonctions, nous avons créé un fichier [*TestingFile*](https://github.com/Antoine7526/F1Repo/tree/main/Test). Ce dernier nous permet dans un premier temps de tiré au hasard une année entre 1950 et 2020, et un grand prix associé à l’année tirée. Cela nous permet de tester nos fonctions sur différentes années et sur différents grands prix.  
  
Une fois nos fonctions nous paraissant opérationnelles, nous avons travaillé à l’élaboration d’un package nommé [*VroumVroum*](https://github.com/CharlineChamp/VroumVroum). Ce dernier nous permet de charger directement les fonctions, ce qui est très utile. Par la suite, après avoir obtenu nos bases de données finales, nous avons décidé de les ajouter directement au package. Cela a permis d’optimiser le temps de chargement de notre application shiny (*cf*. Partie 3).  
  
Pour continuer, nous avons également réalisé des fonctions en [**```Rcpp```**](https://github.com/Antoine7526/F1Repo/tree/main/Rcpp) (en mode *inLine*, en mode classique avec un fichier source *.cpp*). En mode *inLine*, nous avons implémenter une fonction **```add```** permettant l’addition entre trois éléments, et une **```nb_elt```** donnant le nombre d’éléments d’un vecteur de caractères. Dans le fichier *.cpp* nous avons fait deux fonctions calculant des moyennes, **```meanC```** et **```moyenne```**, l’un calculant la moyenne sur un vecteur de **```numeric```**, l’autre calculant la moyenne sur un tableau de **```int```** de taille $n$. Pour donner suite à cela nous avons voulu créer un package [*VroumVroumCpp*](https://github.com/Antoine7526/VroumVroumCpp). Nous nous sommes heurtés à des difficultés qui nous prenaient pas mal de temps. Or, les fonctions implémentées en **```Rcpp```** n'étaient pas utiles à notre projet, car nous ne les utilisions pas. Nous avons donc décidé de mettre cette partie de côté afin d’avancer sur le projet et d’y revenir plus tard si le temps nous le permettait.

## Développement de l'interface Shiny

Afin de terminer notre projet, nous avons créer une interface **```shiny```** pour présenter tout ce qui le constitue, c'est-à-dire par exemple nos graphiques, notre rapport ou encore nos liens sources. Le but étant d’avoir quelque chose d’intuitif nous permettant de le déposer sur internet pour faire perdurer le projet dans le temps. Dans cette partie, nous ne rentrerons pas en détail dans le code. Pour le voir plus en détail il est disponible [ici](https://github.com/Antoine7526/F1Repo/blob/main/Shiny/3.3/shinyapp.R). 
  
L’interface devait comprendre une structure simple : des éléments pour permettre à l’utilisateur de faire le choix des paramètres et une zone où le graphique s’afficherait accompagné d'une petite interprétation. Pour le choix des paramètres, l’utilisateur doit pouvoir choisir l’année qu'il souhaite regarder, et dans certain cas il aura également le choix de sélectionner un grand prix.

Le développement de notre interface web s'est fait en langage **```R```**, à l'aide du package **```shiny```** . Nous nous sommes exclusivement reposés sur cette librairie pour tout ce qui est de l’interface. La librairie **```shiny```** facilite la création d’applications web interactives directement à partir de **```R```**. Elle permet d’héberger des applications autonomes sur une page web ou les intégrer dans des documents **```RMarkdown```**. On peut également étendre les applications **```shiny```** avec des thèmes **```CSS```**, des widgets **```html```** et des actions **```JavaScript```**. Ce package combine la puissance de calcul de **```R```** avec l’interactivité du web.

Un site internet est complétement dédié à la librairie **```shiny```**. Il est composé d’explications pour chaque fonction disponible dans ce package, il y a une partie avec de nombreux articles qui expliquent pas à pas le processus pour construire une interface web. Il nous offre aussi une large galerie de site internet développé sous ce package, vous pouvez le retrouver [ici](https://shiny.rstudio.com/gallery/). Nous nous en sommes beaucoup servi car il nous suffisait d’aller chercher un site sur lequel il y avait ce que nous voulions, puis d’aller voir le code qui était fourni avec pour comprendre les mécanismes.  


Pour vous expliquer brièvement le code, il se constitue de deux grosses fonctions essentielles au fonctionement de l’application : 

- une fonction « ui »
- une fonction « server » 

Dans la fonction « ui » nous retrouvons tout ce qui touche à la mise en page : la disposition des éléments, les couleurs, les polices, les onglets, la manière dont les graphiques s’affichent, etc.   

Comme cité plutôt, lors de ce projet nous avons créé un package nommée [*VroumVroum*](https://github.com/CharlineChamp/VroumVroum). Dans ce package, nous avons toutes nos fonctions utiles aux traitements de nos données, c'est-à-dire à l'affichage de nos différents graphiques. Egalement présent dans ce package, toutes nos données récupérées à l'aide du web scraping. Ainsi dans la fonction « server », nous avons principalement utilisé ce package. Le processus reste le même, nous avons créer une fonction pour chaque graphique à afficher. Dans nos fonctions nous avons commencer par filtrer les données par rapport à l'année sélectionnez par l'utilisateur, ou encore même par le grand prix. Ensuite il nous suffisait d'appeler nos fonctions présentes dans le package et d'y insérer nos données filtrées. Nous avons fait un gain non négligeable de place.  

Une fois l’application créée, il est très facile de la publier sur internet. Nous avons déployer l’application sur un serveur de la librairie shiny : shinyapps.io. 


# Evaluation générale

## Difficultées rencontrées

Discutons maintenant des différentes difficultés que nous avons rencontré lors de ce projet.

Comme vu précedemment, la récupération des données sur le site nous a posé quelques problèmes: la génération automatique des liens pour récupérer, l'incohérence entre le nombre de pilotes aux départs différents du nombre de pilotes à l'arrivée, etc. Cependant un autre problème est apparu lors de ce projet. En effet, durant la moitié du projet, nous avons eu des problèmes d'accents et caractères spéciaux lorsque l'on s'échangeait les données et fichiers R. Ainsi une partie du groupe à du relancer les fichiers du web scraping pour nous permettre d'avoir des données sans caractères spéciaux. Après réflexion, nous nous sommes rendu compte que le problème venait du type d'encodage des fichiers de chacun mais également de nos systèmes d'exploitations qui sont différent.

Deuxièmement un autre souçi est apparu, le Rcpp. La création d'un package est le principal problème pour le Rcpp. (à développer peut être)

Troisèmement, la création du package VroumVroum qui n'a pas été une mince affaire. En effet, nous voulions que les librairies nécessaires dans nos fonctions s'installer automatiquement (si elles ne sont pas déjà présentes) pendant l'installation de notre package. Une fois cela débloqué un second problème a apparu, un conflit de librairies. Nous utilisons dans le package VroumVroum la librairie **```ggplot2```** et **```plotly```**, ainsi un conflit a apparu lors de l'utilisation de la fonction last_plot qui est présente dans ces deux librairies. Pour régler ce problème nous avons dû, au lieu d'importer tous le package **```ggplot2```** et **```plotly```**, n'importer que les fonctions dont nous avions l'utilité.

## Pistes d'améliorations

golem <- shiny
questionnaire

# Conclusion 

Pour finir, nous avons fait le choix de faire une conclusion personnelle sur ce projet plutôt qu'une conclusion générale.

Antoine :



Batiste :

Ce projet m'a beaucoup plu, tant le sujet que le résultat final obtenu. J'ai pu approfondir mes compétences de **```ggplot2```** mais aussi pu découvrir la création de package de **```R``` ** et manipuler de nouvelles librairies notamment **```rvest```** pour le web scraping et l'utilisation de *GitHub*. Je trouve que travailler sous forme de projet avec une grande autonomie est bien plus formateur et plus épanouissant que si on avait eu des cours standards.

Charline :

Pour ma conclusion personnelle, je pense qu’il est important de commencer par dire que j’ai apprécié réaliser ce projet avec mes camarades. Cela m’a permis d’acquérir de nouvelles connaissances en **```R``` ** et de me rendre compte de ce que je suis capable de faire. J'ai pu approndir mes connaissances pour la création d'une application shiny et me découvrir une réelle passion pour cela. De plus, j'ai pu acquérir des connaissances en terme de création de package ou encore même d'utilisation du package ggplot (ou plotly). Etre livré à nous même ne nous a été que bénéfique. 

# Bibliographie

## Web scraping :

1. Site officiel de la Formule 1,
https://www.formula1.com/

2. Site de données sur la Formule 1,
https://www.racing-statistics.com/en

## Traitement des données :

3. "ggplot2 graduation des axes",
http://www.sthda.com/french/wiki/ggplot2-graduation-des-axes-guide-pour-personnaliser-les-etiquettes-des-graduations-logiciel-r-et-visualisation-de-donnees

4. "suppression espaces superflus",2011
http://forums.cirad.fr/logiciel-R/viewtopic.php?t=4446




## Github

nieme. Dossier contenant tous nos fichiers pour le projet,
https://github.com/Antoine7526/F1Repo

nieme+1. Package pour l'interface shiny,
https://github.com/CharlineChamp/VroumVroum



